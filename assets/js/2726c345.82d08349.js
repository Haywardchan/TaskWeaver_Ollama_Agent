"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3450],{286:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>l});var o=n(5893),r=n(1151);const s={},a="Telemetry",i={id:"advanced/telemetry",title:"Telemetry",description:"TaskWeaver now supports tracing with OpenTelemetry,",source:"@site/docs/advanced/telemetry.md",sourceDirName:"advanced",slug:"/advanced/telemetry",permalink:"/TaskWeaver/docs/advanced/telemetry",draft:!1,unlisted:!1,editUrl:"https://github.com/microsoft/TaskWeaver/tree/main/website/docs/advanced/telemetry.md",tags:[],version:"current",frontMatter:{},sidebar:"documentSidebar",previous:{title:"CLI Only Mode",permalink:"/TaskWeaver/docs/advanced/cli_only"},next:{title:"The Plugin-Only Mode",permalink:"/TaskWeaver/docs/plugin/plugin_only"}},c={},l=[{value:"How to enable tracing",id:"how-to-enable-tracing",level:2},{value:"Tracing Infrastructure Configuration",id:"tracing-infrastructure-configuration",level:2},{value:"How to view the metrics",id:"how-to-view-the-metrics",level:2},{value:"How to customize tracing",id:"how-to-customize-tracing",level:2}];function h(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.h1,{id:"telemetry",children:"Telemetry"}),"\n",(0,o.jsx)(t.p,{children:"TaskWeaver now supports tracing with OpenTelemetry,\nwhich is one of the most popular open-source observability frameworks. This allows you to trace the following:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"Interactions between roles, i.e., the Planner, the CodeInterpreter, and the Executor."}),"\n",(0,o.jsx)(t.li,{children:"The time consumed by each role and major components of TaskWeaver."}),"\n",(0,o.jsx)(t.li,{children:"The prompts sent to the LLM and the responses received from the LLM."}),"\n",(0,o.jsx)(t.li,{children:"The status of the tasks and the errors encountered."}),"\n",(0,o.jsx)(t.li,{children:"The number of tokens consumed by each role."}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:"The following screenshot shows a trace of a simple task: analyzing an uploaded file."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Tracing",src:n(7914).Z+"",width:"1859",height:"553"})}),"\n",(0,o.jsx)(t.p,{children:"From this view, you can see the timeline of the task execution, which breaks majorly into\nthree parts:"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"The planning phase, where the Planner decides the sub-tasks to be executed."}),"\n",(0,o.jsx)(t.li,{children:"The code generation and execution phase, where the CodeGenerator generates the code and the CodeExecutor executes it."}),"\n",(0,o.jsx)(t.li,{children:"The reply phase, where the Planner sends the reply to the user."}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:"The bars with a black line represent the critical path of the task execution, which is the longest path through the task execution.\nThis is useful for identifying the bottleneck of the task execution.\nWe can clearly see that, currently, the task execution is dominated by the calls to the LLM."}),"\n",(0,o.jsx)(t.p,{children:"We can click the span (a unit of work in the trace) to see the details of the span, including the logs and the attributes."}),"\n",(0,o.jsx)(t.p,{children:"The screenshot below shows the details of the span of Planner's reply function:"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Tracing Prompt",src:n(1397).Z+"",width:"1746",height:"541"})}),"\n",(0,o.jsx)(t.p,{children:"From this view, we can see the user query, the prompt sent to the LLM, and the tokens consumed (prompt_size and output_size) by the LLM.\nWe also recorded the generated code, the posts between different roles, etc. in the trace."}),"\n",(0,o.jsx)(t.p,{children:"There are also views of the trace, for example the call graph view, which shows the call hierarchy of the spans.\nHere is the call graph of the trace:"}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Tracing Call Graph",src:n(4948).Z+"",width:"1785",height:"326"})}),"\n",(0,o.jsx)(t.h2,{id:"how-to-enable-tracing",children:"How to enable tracing"}),"\n",(0,o.jsxs)(t.p,{children:["Tracing is by default disabled. To enable tracing, you need to install packages required by OpenTelemetry.\nPlease check the ",(0,o.jsx)(t.a,{href:"https://opentelemetry.io/docs/languages/python/",children:"OpenTelemetry website"})," for the installation guide.\nIt basically requires you to install the ",(0,o.jsx)(t.code,{children:"opentelemetry-api"}),", ",(0,o.jsx)(t.code,{children:"opentelemetry-sdk"}),", ",(0,o.jsx)(t.code,{children:"opentelemetry-exporter-otlp"}),",\n",(0,o.jsx)(t.code,{children:"opentelemetry-instrumentation"})," and ",(0,o.jsx)(t.code,{children:"tiktoken"})," packages.\nTo count the number of tokens consumed during task execution, you also need to install the ",(0,o.jsx)(t.a,{href:"https://github.com/openai/tiktoken",children:"tiktoken"})," package.\nWe now only support the tokenizers of the OpenAI models.\nAfter installing the packages, you can enable tracing by setting the ",(0,o.jsx)(t.code,{children:"tracing.enabled=true"})," in the project configuration file.\nThe default tokenizer target model is ",(0,o.jsx)(t.code,{children:"gpt-4"}),", if you want to use another model, you can set the ",(0,o.jsx)(t.code,{children:"tracing.tokenizer_target_model"}),"\nin the project configuration file.\nYou can find the available models in the ",(0,o.jsx)(t.a,{href:"https://github.com/openai/tiktoken/blob/main/tiktoken/model.py",children:"tiktoken code"}),"."]}),"\n",(0,o.jsx)(t.p,{children:"A typical configuration for tracing in the project configuration file is as follows:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-json",children:'{\n  "tracing.enabled": true,\n  "tracing.exporter": "otlp",\n  "tracing.endpoint": "http://127.0.0.1:4317",\n  "tracing.tokenizer_target_model": "gpt-4"\n}\n'})}),"\n",(0,o.jsxs)(t.p,{children:["Next, we need to set up the infrastructure for tracing. The following diagram shows the architecture of a toy tracing system.\nIt is a toy system and the data is not persisted. In a real-world scenario, you need to set up a more robust system.\nThe instrumentation in the TaskWeaver code will send the traces and metrics to the OpenTelemetry collector.\nAn OpenTelemetry collector is a component that receives traces and metrics from the instrumentation, does some processing, and exports them to\nanother collector or a backend. In our case, we configure the collector to export the traces to a ",(0,o.jsx)(t.a,{href:"https://www.jaegertracing.io/",children:"Jaeger"})," backend and the metrics\nto a ",(0,o.jsx)(t.a,{href:"https://prometheus.io/",children:"Prometheus"})," backend.\n",(0,o.jsx)(t.img,{alt:"Tracing Architecture",src:n(2790).Z+"",width:"1027",height:"332"})]}),"\n",(0,o.jsx)(t.p,{children:"You can run the following command to set up the infrastructure:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"cd /TaskWeaver/tracing\ndocker-compose up\n"})}),"\n",(0,o.jsxs)(t.p,{children:["You shall see a bunch of logs from the containers.\nTake a look at the logs to see if there are any errors.\nIf no errors are found, you can access the Prometheus frontend at ",(0,o.jsx)(t.code,{children:"http://localhost:9090"})," and the Jaeger frontend at ",(0,o.jsx)(t.code,{children:"http://localhost:16686"}),".\nIn this setup, we assume you are running the containers on the same machine of TaskWeaver.\nIf you are running the containers on different machines, you need to configure the endpoint of the OpenTelemetry collector in the TaskWeaver configuration file.\nThe default endpoint is ",(0,o.jsx)(t.code,{children:"http://127.0.0.1:4317"}),", you can set the ",(0,o.jsx)(t.code,{children:"tracing.endpoint"})," in the project configuration file to change the endpoint address."]}),"\n",(0,o.jsx)(t.h2,{id:"tracing-infrastructure-configuration",children:"Tracing Infrastructure Configuration"}),"\n",(0,o.jsxs)(t.p,{children:["Both Jaeger and Prometheus are popular open-source monitoring systems. We have prepared a docker-compose file to set up the infrastructure\nin ",(0,o.jsx)(t.code,{children:"/TaskWeaver/tracing_configure/docker-compose.yaml"}),".\nThe content of the file is as follows:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:'version: \'3\'\nservices:\n  optl-collector:\n    image: otel/opentelemetry-collector:0.96.0\n    command: ["--config=/etc/collector-config.yaml"]\n    volumes:\n      - ./collector-config.yaml:/etc/collector-config.yaml\n    ports:\n      - "4317:4317" # Expose the gRPC receiver port for the collector\n    depends_on:\n      - jaeger\n\n  jaeger:\n    image: jaegertracing/all-in-one:1.54\n    ports:\n      - "16686:16686" # Jaeger UI\n\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - "9090:9090" # Prometheus UI\n    volumes:\n      - ./prometheus-config.yml:/etc/prometheus/prometheus.yml\n    command: ["--config.file=/etc/prometheus/prometheus.yml"]\n    depends_on:\n      - optl-collector\n'})}),"\n",(0,o.jsxs)(t.p,{children:["If you read the file, you can see that we use the ",(0,o.jsx)(t.code,{children:"otl/opentelemetry-collector"})," image to set up the OpenTelemetry collector,\nWe only expose the gRPC receiver port for the collector, which is ",(0,o.jsx)(t.code,{children:"4317"}),".\nThe collector configuration file is ",(0,o.jsx)(t.code,{children:"collector-config.yaml"}),", which is mounted to the container.\nThe configuration file is as follows:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:'receivers:\n  otlp:\n    protocols:\n      grpc:\n        endpoint: 0.0.0.0:4317\n      http:\n        endpoint: 0.0.0.0:4318\n\n\nexporters:\n  debug:\n    verbosity: detailed\n  otlp:\n    endpoint: "jaeger:4317"\n    tls:\n      insecure: true\n  prometheus:\n    endpoint: "0.0.0.0:9464"\n\nservice:\n  pipelines:\n    traces:\n      receivers: [otlp]\n      exporters: [otlp]\n    metrics:\n      receivers: [otlp]\n      exporters: [prometheus]\n    logs:\n      receivers: [otlp]\n      exporters: [debug]\n'})}),"\n",(0,o.jsxs)(t.p,{children:["Because Jaeger is compatible with the OpenTelemetry collector, we can export the traces to Jaeger by setting the ",(0,o.jsx)(t.code,{children:"otlp"})," exporter.\nWe also export the metrics to Prometheus by setting the ",(0,o.jsx)(t.code,{children:"prometheus"})," exporter.\nThe ",(0,o.jsx)(t.code,{children:"prometheus-config.yml"})," file is the configuration file for Prometheus, which is as follows:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:'scrape_configs:\n  - job_name: optl-collector\n    scrape_interval: 5s\n    static_configs:\n      - targets: ["optl-collector:9464"]\n'})}),"\n",(0,o.jsx)(t.p,{children:"We only scrape the metrics from the OpenTelemetry collector."}),"\n",(0,o.jsx)(t.h2,{id:"how-to-view-the-metrics",children:"How to view the metrics"}),"\n",(0,o.jsxs)(t.p,{children:["In the first section, we have explained how to view the traces in the Jaeger frontend.\nViewing the metrics in the Prometheus frontend is more complicated as each metric is a time series.\nA time series is a sequence of data points, which are usually timestamped.\nOpenTelemetry allows to add attributes to the metrics, so that you can filter the metrics by the attributes.\nIn our current implementation, we only have one metric called ",(0,o.jsx)(t.code,{children:"prompt_size"})," which records the size of the prompt sent to the LLM.\nIn Prometheus, you should be able to see a time series for the ",(0,o.jsx)(t.code,{children:"prompt_size"})," metric, namely ",(0,o.jsx)(t.code,{children:"prompt_size_total"}),".\n",(0,o.jsx)(t.code,{children:"prompt_size_total"})," is the accumulated prompt size of all the traces which increases monotonically."]}),"\n",(0,o.jsxs)(t.p,{children:["We annotate the traces with the only one attribute called ",(0,o.jsx)(t.code,{children:"direction"}),", which can be either ",(0,o.jsx)(t.code,{children:"input"})," or ",(0,o.jsx)(t.code,{children:"output"}),".\nThey are indicating the input prompt size and the LLM response output size, respectively."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{alt:"Tracing Metrics",src:n(6614).Z+"",width:"1849",height:"748"})}),"\n",(0,o.jsxs)(t.p,{children:["You can query the metrics in the Prometheus frontend. The query language is called PromQL which is quite powerful.\nYou can refer to the ",(0,o.jsx)(t.a,{href:"https://prometheus.io/docs/prometheus/latest/querying/basics/",children:"Prometheus documentation"})," for the details of the query language.\nThe query for the above chart is ",(0,o.jsx)(t.code,{children:"increase(prompt_size_total[10m])"}),",\nwhich means to show the increase of the token consumption in the last 10 minutes sliding window."]}),"\n",(0,o.jsxs)(t.p,{children:["If you want to use Grafana to visualize the metrics, you can set up a Grafana instance and add Prometheus as the data source.\nThis can be done by appending the following content to the ",(0,o.jsx)(t.code,{children:"docker-compose.yaml"})," file:"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-yaml",children:"    grafana:\n        image: grafana/grafana-enterprise:latest\n        ports:\n          - \"3000:3000\" # Grafana UI\n        environment:\n          - GF_SECURITY_ADMIN_PASSWORD=secret # You should change 'secret' to a password of your choosing\n          - GF_USERS_ALLOW_SIGN_UP=false\n        volumes:\n          - grafana_data:/var/lib/grafana\n        depends_on:\n          - prometheus\n\nvolumes:\n  grafana_data:\n"})}),"\n",(0,o.jsx)(t.h2,{id:"how-to-customize-tracing",children:"How to customize tracing"}),"\n",(0,o.jsxs)(t.p,{children:["The instrumentation of TaskWeaver is done by the OpenTelemetry Python SDK.\nSo, if you want to customize the tracing, you need to modify the TaskWeaver code.\nIn TaskWeaver, we add a layer of abstraction to the OpenTelemetry SDK,\nso that it is easier to hide the details of the OpenTelemetry SDK from the TaskWeaver code.\nYou can find the abstraction layer in the ",(0,o.jsx)(t.code,{children:"taskweaver.module.tracing"})," module."]}),"\n",(0,o.jsxs)(t.p,{children:["In the ",(0,o.jsx)(t.code,{children:"taskweaver.module.tracing"})," module, we define the ",(0,o.jsx)(t.code,{children:"Tracing"})," class,\nwhich is a wrapper of the OpenTelemetry SDK. The ",(0,o.jsx)(t.code,{children:"Tracing"})," class provides the following methods:"]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:"set_span_status: Set the status of the span."}),"\n",(0,o.jsx)(t.li,{children:"set_span_attribute: Set the attribute of the span."}),"\n",(0,o.jsx)(t.li,{children:"set_span_exception: Set the exception of the span."}),"\n",(0,o.jsx)(t.li,{children:"add_prompt_size: Add the prompt size to the span."}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["In addition, we define the decorator ",(0,o.jsx)(t.code,{children:"tracing_decorator"})," (or the non-class version ",(0,o.jsx)(t.code,{children:"tracing_decorator_non_class"}),")\nto trace the function calls.\nWhen you need to create a context for tracing, you can use"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:'with get_tracer().start_as_current_span("span_name") as span:\n    # your code\n'})}),"\n",(0,o.jsx)(t.p,{children:"When you need to trace a function, you can use"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-python",children:"@tracing_decorator\ndef your_function(self, *args, **kwargs):\n    # your code\n"})})]})}function d(e={}){const{wrapper:t}={...(0,r.a)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},6614:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/prometheus_chart-0860159d15ddc3fa0753c4eccb4b190d.png"},7914:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/trace-f562ffc9ba2eba5acb5f8d9403c327ec.png"},4948:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/trace_graph-b5a2d47a94e2653a08ec325c0131954d.png"},1397:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/trace_prompt-1a16096cc7cf481796e058a691167287.png"},2790:(e,t,n)=>{n.d(t,{Z:()=>o});const o=n.p+"assets/images/tracing-arch-85baf8dedb28553470d3ae733f0f28b3.png"},1151:(e,t,n)=>{n.d(t,{Z:()=>i,a:()=>a});var o=n(7294);const r={},s=o.createContext(r);function a(e){const t=o.useContext(s);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),o.createElement(s.Provider,{value:t},e.children)}}}]);